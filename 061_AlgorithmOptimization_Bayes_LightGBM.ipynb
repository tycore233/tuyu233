{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# fileName = open(r\"D:/Python/毕设实验部分/data/临时特征集/特征集_209维特征_已做特征选择_零填充_已做过采样.csv\")\n",
    "# data = pd.read_csv(fileName)\n",
    "# data.head()\n",
    "\n",
    "\n",
    "feature = pd.read_table('/Users/tuyu/000000毕业设计/Flight_Delay/Train_Feature/final_feature.csv',sep=',',encoding='gb2312')\n",
    "\n",
    "del(feature['本时段离港平均延误时长'])\n",
    "del(feature['上一时段离港平均延误时长'])\n",
    "del(feature['航班编号'])\n",
    "# 1.前序延误 = 前序航班 实际到达时间 - 计划到达时间\n",
    "# 2.起飞间隔 = 当前航班的计划起飞时间 - 前序航班实际到达时间\n",
    "feature['起飞间隔'] = feature['起飞间隔'].fillna(0)\n",
    "feature['前序延误'] = feature['前序延误'].fillna(0)\n",
    "feature['出发机场天气得分'] = feature['出发机场天气得分'].interpolate()\n",
    "feature['到达机场天气得分'] = feature['到达机场天气得分'].interpolate()\n",
    "feature['平均延误时间'] = feature['平均延误时间'].interpolate()\n",
    "feature['最大延误时间'] = feature['最大延误时间'].interpolate()\n",
    "feature['延误时间中位数'] = feature['延误时间中位数'].interpolate()\n",
    "feature['延误时间标准差'] = feature['延误时间标准差'].interpolate()\n",
    "\n",
    "feature['本时段计划离港航班数'] = feature['本时段计划离港航班数'].fillna(feature['本时段计划离港航班数'].mean())\n",
    "feature['本时段实际离港航班数'] = feature['本时段实际离港航班数'].fillna(feature['本时段实际离港航班数'].mean())\n",
    "feature['本时段进港延误时长'] = feature['本时段进港延误时长'].fillna(feature['本时段进港延误时长'].mean())\n",
    "feature['本时段实际进港延误航班数'] = feature['本时段实际进港延误航班数'].fillna(feature['本时段实际进港延误航班数'].mean())\n",
    "feature['本时段离港延误时长'] = feature['本时段离港延误时长'].fillna(feature['本时段离港延误时长'].mean())\n",
    "feature['本时段离港延误率'] = feature['本时段离港延误率'].fillna(feature['本时段离港延误率'].mean())\n",
    "feature['上一时段进港延误时长'] = feature['上一时段进港延误时长'].fillna(feature['上一时段进港延误时长'].mean())\n",
    "feature['上一时段离港延误时长'] = feature['上一时段离港延误时长'].fillna(feature['上一时段离港延误时长'].mean())\n",
    "feature['上一时段实际进港航班数'] = feature['上一时段实际进港航班数'].fillna(feature['上一时段实际进港航班数'].mean())\n",
    "feature['上一时段进港延误率'] = feature['上一时段进港延误率'].fillna(feature['上一时段进港延误率'].mean())\n",
    "\n",
    "# feature = feature.sample(frac=0.1, replace=False, random_state=None,axis=0)\n",
    "feature0 = feature[feature['标签'] == 0]\n",
    "feature0new = feature0.sample(frac=0.15, replace=False, random_state=None,axis=0)\n",
    "feature1 = feature[feature['标签'] == 1]\n",
    "data = pd.concat([feature0new,feature1],axis=0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (1292410, 35)\n",
      "Test shape: (323103, 35)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>计划起飞时间</th>\n",
       "      <th>计划到达时间</th>\n",
       "      <th>计划起飞时刻</th>\n",
       "      <th>计划到达时刻</th>\n",
       "      <th>计划飞行时间</th>\n",
       "      <th>起飞间隔</th>\n",
       "      <th>前序延误</th>\n",
       "      <th>平均延误时间</th>\n",
       "      <th>最大延误时间</th>\n",
       "      <th>延误时间中位数</th>\n",
       "      <th>...</th>\n",
       "      <th>本时段计划离港航班数</th>\n",
       "      <th>本时段实际离港航班数</th>\n",
       "      <th>本时段进港延误时长</th>\n",
       "      <th>本时段实际进港延误航班数</th>\n",
       "      <th>本时段离港延误时长</th>\n",
       "      <th>本时段离港延误率</th>\n",
       "      <th>上一时段进港延误时长</th>\n",
       "      <th>上一时段离港延误时长</th>\n",
       "      <th>上一时段实际进港航班数</th>\n",
       "      <th>上一时段进港延误率</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1352958</td>\n",
       "      <td>17231</td>\n",
       "      <td>17232</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-1.216667</td>\n",
       "      <td>-0.366667</td>\n",
       "      <td>1.333947</td>\n",
       "      <td>20.083333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>-6.283333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.583333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.783333e+00</td>\n",
       "      <td>20.383333</td>\n",
       "      <td>15.633042</td>\n",
       "      <td>0.020608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>976806</td>\n",
       "      <td>17083</td>\n",
       "      <td>17083</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>0.922169</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>15.393169</td>\n",
       "      <td>15.438519</td>\n",
       "      <td>-3.516667</td>\n",
       "      <td>0.257175</td>\n",
       "      <td>1.391369</td>\n",
       "      <td>0.019545</td>\n",
       "      <td>-4.500000e-01</td>\n",
       "      <td>2.531482</td>\n",
       "      <td>15.633042</td>\n",
       "      <td>0.020608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>406338</td>\n",
       "      <td>17150</td>\n",
       "      <td>17150</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>1.718756</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>-0.550000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.233333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.783333e+00</td>\n",
       "      <td>11.316667</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>368992</td>\n",
       "      <td>16830</td>\n",
       "      <td>16830</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.468756</td>\n",
       "      <td>11.966667</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.438519</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.016667</td>\n",
       "      <td>0.019545</td>\n",
       "      <td>-3.469447e-18</td>\n",
       "      <td>2.531482</td>\n",
       "      <td>15.633042</td>\n",
       "      <td>0.020608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>629642</td>\n",
       "      <td>16953</td>\n",
       "      <td>16953</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>-0.116667</td>\n",
       "      <td>1.632762</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>...</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>14.050000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>48.816667</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>8.533333e+00</td>\n",
       "      <td>33.283333</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.178571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         计划起飞时间  计划到达时间  计划起飞时刻  计划到达时刻    计划飞行时间      起飞间隔      前序延误  \\\n",
       "1352958   17231   17232      23       1  2.000000 -1.216667 -0.366667   \n",
       "976806    17083   17083       1       2  1.750000  0.750000 -0.083333   \n",
       "406338    17150   17150      13      15  2.250000  0.866667  0.216667   \n",
       "368992    16830   16830       2       3  1.250000  0.633333  0.200000   \n",
       "629642    16953   16953      13      15  2.166667  1.200000 -0.116667   \n",
       "\n",
       "           平均延误时间     最大延误时间   延误时间中位数  ...  本时段计划离港航班数  本时段实际离港航班数  \\\n",
       "1352958  1.333947  20.083333  0.100000  ...   35.000000   35.000000   \n",
       "976806   0.922169  10.000000  0.200000  ...   15.393169   15.438519   \n",
       "406338   1.718756  10.000000  0.775000  ...   11.000000   11.000000   \n",
       "368992   1.468756  11.966667  0.233333  ...    1.000000   15.438519   \n",
       "629642   1.632762  10.000000  0.733333  ...   17.000000    9.000000   \n",
       "\n",
       "         本时段进港延误时长  本时段实际进港延误航班数  本时段离港延误时长  本时段离港延误率    上一时段进港延误时长  \\\n",
       "1352958  -6.283333      0.000000  19.583333  0.000000 -5.783333e+00   \n",
       "976806   -3.516667      0.257175   1.391369  0.019545 -4.500000e-01   \n",
       "406338   -0.550000      0.000000   4.233333  0.000000 -1.783333e+00   \n",
       "368992   -0.400000      0.000000  -0.016667  0.019545 -3.469447e-18   \n",
       "629642   14.050000      5.000000  48.816667  0.470588  8.533333e+00   \n",
       "\n",
       "         上一时段离港延误时长  上一时段实际进港航班数  上一时段进港延误率  \n",
       "1352958   20.383333    15.633042   0.020608  \n",
       "976806     2.531482    15.633042   0.020608  \n",
       "406338    11.316667    31.000000   0.000000  \n",
       "368992     2.531482    15.633042   0.020608  \n",
       "629642    33.283333    23.000000   0.178571  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train = data[data['ORIGIN'] == 'train']\n",
    "# test = data[data['ORIGIN'] == 'test']\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(data, test_size=0.2, random_state=7)\n",
    "\n",
    "train_labels = np.array(train['标签'].astype(np.int32)).reshape((-1,))\n",
    "test_labels = np.array(test['标签'].astype(np.int32)).reshape((-1,))\n",
    "\n",
    "train = train.drop(['标签'], axis = 1)\n",
    "test = test.drop(['标签'], axis = 1)\n",
    "\n",
    "features = np.array(train)\n",
    "test_features = np.array(test)\n",
    "labels = train_labels[:]\n",
    "\n",
    "print('Train shape:', train.shape)\n",
    "print('Test shape:', test.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import csv\n",
    "from hyperopt import STATUS_OK\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "train_set = lgb.Dataset(features, label = labels)\n",
    "N_folds = 3\n",
    "def objective(params, n_folds = N_folds):\n",
    "    global ITERATION\n",
    "    ITERATION += 1\n",
    "    \n",
    "    subsample = params['boosting_type'].get('subsample', 1.0)\n",
    "    params['boosting_type'] = params['boosting_type']['boosting_type']\n",
    "    params['subsample'] = subsample\n",
    "    \n",
    "    for parameter_name in ['num_leaves', 'subsample_for_bin', 'min_child_samples']:\n",
    "        params[parameter_name] = int(params[parameter_name])\n",
    "    start = timer()\n",
    "    cv_results = lgb.cv(params, train_set, num_boost_round=100, nfold=10, metrics='auc',\n",
    "          early_stopping_rounds = 100, verbose_eval = False, seed = 42)\n",
    "    run_time = timer() - start\n",
    "    \n",
    "    best_score = np.max(cv_results['auc-mean'])\n",
    "    loss = 1 - best_score\n",
    "    n_estimators = int(np.argmax(cv_results['auc-mean']) + 1)\n",
    "    \n",
    "    of_connection = open(out_file, 'a')\n",
    "    writer = csv.writer(of_connection)\n",
    "    writer.writerow([loss, params, ITERATION, n_estimators, run_time])\n",
    "    \n",
    "    return {'loss': loss, 'params': params, 'iteration': ITERATION,\n",
    "           'estimators': n_estimators, 'train_time': run_time, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "from hyperopt.pyll.stochastic import sample\n",
    "space = {'class_weight': hp.choice('class_weight', [None, 'balanced']),\n",
    "        'boosting_type': hp.choice('boosting_type', [{'boosting_type': 'gbdt', 'subsample': hp.uniform('gdbt_subsample', 0.5, 1)},\n",
    "                                                    {'boosting_type': 'dart', 'subsample': hp.uniform('dart_subsample', 0.5, 1)},\n",
    "                                                    {'boosting_type': 'goss', 'subsample': 1.0}]),\n",
    "        'num_leaves': hp.quniform('num_leaves', 30, 150, 1),\n",
    "        'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n",
    "        'subsample_for_bin': hp.quniform('subsample_for_bin', 20000, 300000, 20000),\n",
    "         'min_child_samples': hp.quniform('min_child_samples', 20, 500, 5),\n",
    "         'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.0),\n",
    "         'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0),\n",
    "         'colsample_bytree': hp.uniform('colsample_by_tree', 0.6, 1.0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning]                                 \n",
      "Auto-choosing row-wise multi-threading, the overhead of testing was 0.090198 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info]                                    \n",
      "Total Bins 4374                                      \n",
      "[LightGBM] [Info]                                    \n",
      "Number of data points in the train set: 1163169, number of used features: 35\n",
      "[LightGBM] [Info]                                    \n",
      "Using GOSS                                           \n",
      "[LightGBM] [Warning]                                 \n",
      "Auto-choosing row-wise multi-threading, the overhead of testing was 0.095720 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info]                                    \n",
      "Total Bins 4374                                      \n",
      "[LightGBM] [Info]                                    \n",
      "Number of data points in the train set: 1163169, number of used features: 35\n",
      "[LightGBM] [Info]                                    \n",
      "Using GOSS                                           \n",
      "[LightGBM] [Warning]                                 \n",
      "Auto-choosing row-wise multi-threading, the overhead of testing was 0.095949 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info]                                    \n",
      "Total Bins 4374                                      \n",
      "[LightGBM] [Info]                                    \n",
      "Number of data points in the train set: 1163169, number of used features: 35\n",
      "[LightGBM] [Info]                                    \n",
      "Using GOSS                                           \n",
      "[LightGBM] [Warning]                                 \n",
      "Auto-choosing row-wise multi-threading, the overhead of testing was 0.096037 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info]                                    \n",
      "Total Bins 4374                                      \n",
      "[LightGBM] [Info]                                    \n",
      "Number of data points in the train set: 1163169, number of used features: 35\n",
      "[LightGBM] [Info]                                    \n",
      "Using GOSS                                           \n",
      "[LightGBM] [Warning]                                 \n",
      "Auto-choosing row-wise multi-threading, the overhead of testing was 0.107226 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info]                                    \n",
      "Total Bins 4374                                      \n",
      "[LightGBM] [Info]                                    \n",
      "Number of data points in the train set: 1163169, number of used features: 35\n",
      "[LightGBM] [Info]                                    \n",
      "Using GOSS                                           \n",
      "[LightGBM] [Warning]                                 \n",
      "Auto-choosing col-wise multi-threading, the overhead of testing was 0.495582 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info]                                    \n",
      "Total Bins 4374                                      \n",
      "[LightGBM] [Info]                                    \n",
      "Number of data points in the train set: 1163169, number of used features: 35\n",
      "[LightGBM] [Info]                                    \n",
      "Using GOSS                                           \n",
      "[LightGBM] [Warning]                                 \n",
      "Auto-choosing row-wise multi-threading, the overhead of testing was 0.114721 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info]                                    \n",
      "Total Bins 4374                                      \n",
      "[LightGBM] [Info]                                    \n",
      "Number of data points in the train set: 1163169, number of used features: 35\n",
      "[LightGBM] [Info]                                    \n",
      "Using GOSS                                           \n",
      "[LightGBM] [Warning]                                 \n",
      "Auto-choosing row-wise multi-threading, the overhead of testing was 0.126416 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info]                                    \n",
      "Total Bins 4374                                      \n",
      "[LightGBM] [Info]                                    \n",
      "Number of data points in the train set: 1163169, number of used features: 35\n",
      "[LightGBM] [Info]                                    \n",
      "Using GOSS                                           \n",
      "[LightGBM] [Warning]                                 \n",
      "Auto-choosing row-wise multi-threading, the overhead of testing was 0.096854 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info]                                    \n",
      "Total Bins 4374                                      \n",
      "[LightGBM] [Info]                                    \n",
      "Number of data points in the train set: 1163169, number of used features: 35\n",
      "[LightGBM] [Info]                                    \n",
      "Using GOSS                                           \n",
      "[LightGBM] [Warning]                                 \n",
      "Auto-choosing row-wise multi-threading, the overhead of testing was 0.133784 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info]                                    \n",
      "Total Bins 4374                                      \n",
      "[LightGBM] [Info]                                    \n",
      "Number of data points in the train set: 1163169, number of used features: 35\n",
      "[LightGBM] [Info]                                    \n",
      "Using GOSS                                           \n",
      "[LightGBM] [Info]                                    \n",
      "Start training from score 0.342318                   \n",
      "[LightGBM] [Info]                                    \n",
      "Start training from score 0.342318                   \n",
      "[LightGBM] [Info]                                    \n",
      "Start training from score 0.342318                   \n",
      "[LightGBM] [Info]                                    \n",
      "Start training from score 0.342318                   \n",
      "[LightGBM] [Info]                                    \n",
      "Start training from score 0.342318                   \n",
      "[LightGBM] [Info]                                    \n",
      "Start training from score 0.342318                   \n",
      "[LightGBM] [Info]                                    \n",
      "Start training from score 0.342319                   \n",
      "[LightGBM] [Info]                                    \n",
      "Start training from score 0.342319                   \n",
      "[LightGBM] [Info]                                    \n",
      "Start training from score 0.342319                   \n",
      "[LightGBM] [Info]                                    \n",
      "Start training from score 0.342319                   \n",
      "[LightGBM] [Warning]                                                              \n",
      "Auto-choosing col-wise multi-threading, the overhead of testing was 0.193837 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info]                                                                 \n",
      "Total Bins 4374                                                                   \n",
      "[LightGBM] [Info]                                                                 \n",
      "Number of data points in the train set: 1163169, number of used features: 35      \n",
      "[LightGBM] [Info]                                                                 \n",
      "Using GOSS                                                                        \n",
      "[LightGBM] [Warning]                                                              \n",
      "Auto-choosing col-wise multi-threading, the overhead of testing was 0.227238 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info]                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Bins 4374                                                                   \n",
      "[LightGBM] [Info]                                                                 \n",
      "Number of data points in the train set: 1163169, number of used features: 35      \n",
      "[LightGBM] [Info]                                                                 \n",
      "Using GOSS                                                                        \n",
      "[LightGBM] [Warning]                                                              \n",
      "Auto-choosing col-wise multi-threading, the overhead of testing was 0.179975 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info]                                                                 \n",
      "Total Bins 4374                                                                   \n",
      "[LightGBM] [Info]                                                                 \n",
      "Number of data points in the train set: 1163169, number of used features: 35      \n",
      "[LightGBM] [Info]                                                                 \n",
      "Using GOSS                                                                        \n",
      "[LightGBM] [Warning]                                                              \n",
      "Auto-choosing col-wise multi-threading, the overhead of testing was 0.208750 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info]                                                                 \n",
      "Total Bins 4374                                                                   \n",
      "[LightGBM] [Info]                                                                 \n",
      "Number of data points in the train set: 1163169, number of used features: 35      \n",
      "[LightGBM] [Info]                                                                 \n",
      "Using GOSS                                                                        \n",
      "[LightGBM] [Warning]                                                              \n",
      "Auto-choosing col-wise multi-threading, the overhead of testing was 0.271703 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info]                                                                 \n",
      "Total Bins 4374                                                                   \n",
      "[LightGBM] [Info]                                                                 \n",
      "Number of data points in the train set: 1163169, number of used features: 35      \n",
      "[LightGBM] [Info]                                                                 \n",
      "Using GOSS                                                                        \n",
      "[LightGBM] [Warning]                                                              \n",
      "Auto-choosing col-wise multi-threading, the overhead of testing was 0.247247 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info]                                                                 \n",
      "Total Bins 4374                                                                   \n",
      "[LightGBM] [Info]                                                                 \n",
      "Number of data points in the train set: 1163169, number of used features: 35      \n",
      "[LightGBM] [Info]                                                                 \n",
      "Using GOSS                                                                        \n",
      "[LightGBM] [Warning]                                                              \n",
      "Auto-choosing row-wise multi-threading, the overhead of testing was 0.095232 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info]                                                                 \n",
      "Total Bins 4374                                                                   \n",
      "[LightGBM] [Info]                                                                 \n",
      "Number of data points in the train set: 1163169, number of used features: 35      \n",
      "[LightGBM] [Info]                                                                 \n",
      "Using GOSS                                                                        \n",
      "[LightGBM] [Warning]                                                              \n",
      "Auto-choosing col-wise multi-threading, the overhead of testing was 0.180048 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info]                                                                 \n",
      "Total Bins 4374                                                                   \n",
      "[LightGBM] [Info]                                                                 \n",
      "Number of data points in the train set: 1163169, number of used features: 35      \n",
      "[LightGBM] [Info]                                                                 \n",
      "Using GOSS                                                                        \n",
      "[LightGBM] [Warning]                                                              \n",
      "Auto-choosing col-wise multi-threading, the overhead of testing was 0.222226 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info]                                                                 \n",
      "Total Bins 4374                                                                   \n",
      "[LightGBM] [Info]                                                                 \n",
      "Number of data points in the train set: 1163169, number of used features: 35      \n",
      "[LightGBM] [Info]                                                                 \n",
      "Using GOSS                                                                        \n",
      "[LightGBM] [Warning]                                                              \n",
      "Auto-choosing col-wise multi-threading, the overhead of testing was 0.206272 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info]                                                                 \n",
      "Total Bins 4374                                                                   \n",
      "[LightGBM] [Info]                                                                 \n",
      "Number of data points in the train set: 1163169, number of used features: 35      \n",
      "[LightGBM] [Info]                                                                 \n",
      "Using GOSS                                                                        \n",
      "[LightGBM] [Info]                                                                 \n",
      "Start training from score 0.342318                                                \n",
      "[LightGBM] [Info]                                                                 \n",
      "Start training from score 0.342318                                                \n",
      "[LightGBM] [Info]                                                                 \n",
      "Start training from score 0.342318                                                \n",
      "[LightGBM] [Info]                                                                 \n",
      "Start training from score 0.342318                                                \n",
      "[LightGBM] [Info]                                                                 \n",
      "Start training from score 0.342318                                                \n",
      "[LightGBM] [Info]                                                                 \n",
      "Start training from score 0.342318                                                \n",
      "[LightGBM] [Info]                                                                 \n",
      "Start training from score 0.342319                                                \n",
      "[LightGBM] [Info]                                                                 \n",
      "Start training from score 0.342319                                                \n",
      "[LightGBM] [Info]                                                                 \n",
      "Start training from score 0.342319                                                \n",
      "[LightGBM] [Info]                                                                 \n",
      "Start training from score 0.342319                                                \n",
      "100%|██████████| 2/2 [04:44<00:00, 142.14s/trial, best loss: 0.04997650730623171] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.04997650730623171,\n",
       " 'params': {'boosting_type': 'goss',\n",
       "  'class_weight': None,\n",
       "  'colsample_bytree': 0.7816680870637424,\n",
       "  'learning_rate': 0.03457647873038711,\n",
       "  'min_child_samples': 340,\n",
       "  'num_leaves': 68,\n",
       "  'reg_alpha': 0.9328679988478337,\n",
       "  'reg_lambda': 0.727725743177325,\n",
       "  'subsample_for_bin': 140000,\n",
       "  'subsample': 1.0},\n",
       " 'iteration': 2,\n",
       " 'estimators': 100,\n",
       " 'train_time': 141.4368505370221,\n",
       " 'status': 'ok'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hyperopt import fmin\n",
    "from hyperopt import tpe\n",
    "tpe_algorithm = tpe.suggest\n",
    "\n",
    "from hyperopt import Trials\n",
    "bayes_trials = Trials()\n",
    "out_file = 'gbm_trials.csv'\n",
    "of_connection = open(out_file, 'w')\n",
    "writer = csv.writer(of_connection)\n",
    "\n",
    "writer.writerow(['loss', 'params', 'iteration', 'estimators', 'train_time'])\n",
    "of_connection.close()\n",
    "# Global variable\n",
    "global  ITERATION\n",
    "\n",
    "ITERATION = 0\n",
    "\n",
    "max_evals = 2\n",
    "# Run optimization\n",
    "best = fmin(fn = objective, space = space, algo = tpe.suggest, max_evals = max_evals, trials = bayes_trials, rstate = np.random.RandomState(42))\n",
    "\n",
    "# Sort the trials with lowest loss (highest AUC) first\n",
    "bayes_trials_results = sorted(bayes_trials.results, key = lambda x: x['loss'])\n",
    "bayes_trials_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>params</th>\n",
       "      <th>iteration</th>\n",
       "      <th>estimators</th>\n",
       "      <th>train_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.049977</td>\n",
       "      <td>{'boosting_type': 'goss', 'class_weight': None...</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>141.436851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.051551</td>\n",
       "      <td>{'boosting_type': 'goss', 'class_weight': None...</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>142.784389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss                                             params  iteration  \\\n",
       "0  0.049977  {'boosting_type': 'goss', 'class_weight': None...          2   \n",
       "1  0.051551  {'boosting_type': 'goss', 'class_weight': None...          1   \n",
       "\n",
       "   estimators  train_time  \n",
       "0         100  141.436851  \n",
       "1         100  142.784389  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#保存结果\n",
    "results = pd.read_csv('gbm_trials.csv')\n",
    "results.sort_values('loss', ascending = True, inplace = True)\n",
    "results.reset_index(inplace = True, drop = True)\n",
    "print(results.shape)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'goss',\n",
       " 'class_weight': None,\n",
       " 'colsample_bytree': 0.7816680870637424,\n",
       " 'learning_rate': 0.03457647873038711,\n",
       " 'min_child_samples': 340,\n",
       " 'num_leaves': 68,\n",
       " 'reg_alpha': 0.9328679988478337,\n",
       " 'reg_lambda': 0.727725743177325,\n",
       " 'subsample_for_bin': 140000,\n",
       " 'subsample': 1.0}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "ast.literal_eval(results.loc[0, 'params'])\n",
    "# 出于安全考虑，对字符串进行类型转换的时候，最好使用ast.literal_eval()函数, 而不是直接用eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='goss', colsample_bytree=0.7816680870637424,\n",
       "               learning_rate=0.03457647873038711, min_child_samples=340,\n",
       "               num_leaves=68, objective='binary', random_state=42,\n",
       "               reg_alpha=0.9328679988478337, reg_lambda=0.727725743177325,\n",
       "               subsample_for_bin=140000)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_bayes_estimators = int(results.loc[0, 'estimators'])\n",
    "best_bayes_params = ast.literal_eval(results.loc[0, 'params']).copy()\n",
    "best_bayes_model = lgb.LGBMClassifier(n_estimators=best_bayes_estimators, n_jobs=-1,\n",
    "                                     objective='binary', **best_bayes_params, random_state=42)\n",
    "best_bayes_model.fit(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#保存模型\n",
    "\n",
    "f= open('/Users/tuyu/000000毕业设计/Flight_Delay/Model/Bayes_model/best_bayes_LightGBM.pickle','wb')\n",
    "pickle.dump(best_bayes_model,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 0, 0, 1], dtype=int32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = best_bayes_model.predict(test_features)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93    225796\n",
      "           1       0.80      0.91      0.85     97307\n",
      "\n",
      "    accuracy                           0.91    323103\n",
      "   macro avg       0.88      0.91      0.89    323103\n",
      "weighted avg       0.91      0.91      0.91    323103\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report \n",
    "test_labels = test_labels.tolist()\n",
    "test_labels = np.array([i for i in test_labels])\n",
    "print(classification_report(preds, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "验证样本的准确率: 0.9067\n",
      "('ks', 0.7642466998059849)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "testAccuracy = metrics.accuracy_score(test_labels, preds)\n",
    "print(\"验证样本的准确率: %.4f\" % testAccuracy)\n",
    "\n",
    "\n",
    "def ks(y_predicted, y_true):\n",
    "    label=y_true\n",
    "    #label = y_true.get_label()\n",
    "    fpr,tpr,thres = metrics.roc_curve(label,y_predicted,pos_label=1)\n",
    "    return 'ks',abs(fpr - tpr).max()\n",
    "ks_score = ks(preds, test_labels)\n",
    "print(ks_score) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.93    214856\n",
      "           1       0.85      0.86      0.86    108247\n",
      "\n",
      "    accuracy                           0.90    323103\n",
      "   macro avg       0.89      0.89      0.89    323103\n",
      "weighted avg       0.90      0.90      0.90    323103\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction_test_predprob = best_bayes_model.predict_proba(test_features)[:,1]\n",
    "\n",
    "lgb_offline=(prediction_test_predprob >= 0.35) *1\n",
    "from sklearn.metrics import classification_report \n",
    "print(classification_report(lgb_offline, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>计划起飞时间</th>\n",
       "      <th>计划到达时间</th>\n",
       "      <th>计划起飞时刻</th>\n",
       "      <th>计划到达时刻</th>\n",
       "      <th>计划飞行时间</th>\n",
       "      <th>起飞间隔</th>\n",
       "      <th>前序延误</th>\n",
       "      <th>平均延误时间</th>\n",
       "      <th>最大延误时间</th>\n",
       "      <th>延误时间中位数</th>\n",
       "      <th>...</th>\n",
       "      <th>本时段进港延误时长</th>\n",
       "      <th>本时段实际进港延误航班数</th>\n",
       "      <th>本时段离港延误时长</th>\n",
       "      <th>本时段离港延误率</th>\n",
       "      <th>上一时段进港延误时长</th>\n",
       "      <th>上一时段离港延误时长</th>\n",
       "      <th>上一时段实际进港航班数</th>\n",
       "      <th>上一时段进港延误率</th>\n",
       "      <th>预测值</th>\n",
       "      <th>标签</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1465970</td>\n",
       "      <td>17215</td>\n",
       "      <td>17215</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>1.616667</td>\n",
       "      <td>-0.366667</td>\n",
       "      <td>0.658844</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>...</td>\n",
       "      <td>10.550000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.866667</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1567359</td>\n",
       "      <td>16913</td>\n",
       "      <td>16913</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.416667</td>\n",
       "      <td>12.950000</td>\n",
       "      <td>-0.533333</td>\n",
       "      <td>0.830704</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.133333</td>\n",
       "      <td>0.257175</td>\n",
       "      <td>1.391369</td>\n",
       "      <td>0.019545</td>\n",
       "      <td>-0.566667</td>\n",
       "      <td>2.531482</td>\n",
       "      <td>15.633042</td>\n",
       "      <td>0.020608</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1603119</td>\n",
       "      <td>17169</td>\n",
       "      <td>17169</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>-1.200000</td>\n",
       "      <td>2.116667</td>\n",
       "      <td>1.309294</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>...</td>\n",
       "      <td>5.416667</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>10.883333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>1.883333</td>\n",
       "      <td>9.300000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1536619</td>\n",
       "      <td>16894</td>\n",
       "      <td>16894</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>-1.566667</td>\n",
       "      <td>2.566667</td>\n",
       "      <td>0.802233</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.516667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>2.016667</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1455481</td>\n",
       "      <td>17110</td>\n",
       "      <td>17110</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>2.083333</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.736416</td>\n",
       "      <td>12.883333</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.383333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.083333</td>\n",
       "      <td>10.733333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1428786</td>\n",
       "      <td>16848</td>\n",
       "      <td>16848</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>-0.433333</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.960935</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.331113</td>\n",
       "      <td>0.257175</td>\n",
       "      <td>2.016667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.342989</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>15.633042</td>\n",
       "      <td>0.020608</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1547718</td>\n",
       "      <td>17058</td>\n",
       "      <td>17058</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>1.650000</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>1.068836</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>16.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.966667</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1354914</td>\n",
       "      <td>17002</td>\n",
       "      <td>17002</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>-0.816667</td>\n",
       "      <td>-0.433333</td>\n",
       "      <td>0.567647</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.257175</td>\n",
       "      <td>3.650000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>2.531482</td>\n",
       "      <td>15.633042</td>\n",
       "      <td>0.020608</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>778010</td>\n",
       "      <td>17013</td>\n",
       "      <td>17013</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>1.583333</td>\n",
       "      <td>-1.533333</td>\n",
       "      <td>2.450000</td>\n",
       "      <td>1.698457</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.258333</td>\n",
       "      <td>...</td>\n",
       "      <td>4.933333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>2.531482</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1575451</td>\n",
       "      <td>17287</td>\n",
       "      <td>17287</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>2.777248</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.316667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.366667</td>\n",
       "      <td>24.733333</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30140 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         计划起飞时间  计划到达时间  计划起飞时刻  计划到达时刻    计划飞行时间       起飞间隔      前序延误  \\\n",
       "1465970   17215   17215       3       6  3.333333   1.616667 -0.366667   \n",
       "1567359   16913   16913       1       3  1.416667  12.950000 -0.533333   \n",
       "1603119   17169   17169      11      13  1.500000  -1.200000  2.116667   \n",
       "1536619   16894   16894      11      13  1.666667  -1.566667  2.566667   \n",
       "1455481   17110   17110       7       9  2.083333   0.183333  0.150000   \n",
       "...         ...     ...     ...     ...       ...        ...       ...   \n",
       "1428786   16848   16848       1       2  0.750000  -0.433333  0.266667   \n",
       "1547718   17058   17058      11      16  4.833333   1.650000 -0.400000   \n",
       "1354914   17002   17002       0       2  2.250000  -0.816667 -0.433333   \n",
       "778010    17013   17013       8      10  1.583333  -1.533333  2.450000   \n",
       "1575451   17287   17287      12      14  2.250000   0.916667 -0.250000   \n",
       "\n",
       "           平均延误时间     最大延误时间   延误时间中位数  ...  本时段进港延误时长  本时段实际进港延误航班数  \\\n",
       "1465970  0.658844   7.400000  0.233333  ...  10.550000      0.000000   \n",
       "1567359  0.830704  10.000000  0.050000  ...  -2.133333      0.257175   \n",
       "1603119  1.309294  10.000000  0.316667  ...   5.416667      3.000000   \n",
       "1536619  0.802233  10.000000  0.300000  ...  -0.400000      0.000000   \n",
       "1455481  0.736416  12.883333  0.233333  ...   0.366667      0.000000   \n",
       "...           ...        ...       ...  ...        ...           ...   \n",
       "1428786  0.960935  10.000000  0.200000  ...  -3.331113      0.257175   \n",
       "1547718  1.068836  10.000000  0.250000  ...  16.133333      0.000000   \n",
       "1354914  0.567647  10.000000  0.266667  ...  -0.200000      0.257175   \n",
       "778010   1.698457  10.000000  1.258333  ...   4.933333      0.000000   \n",
       "1575451  2.777248  10.000000  1.100000  ...   1.316667      0.000000   \n",
       "\n",
       "         本时段离港延误时长  本时段离港延误率  上一时段进港延误时长  上一时段离港延误时长  上一时段实际进港航班数  上一时段进港延误率  \\\n",
       "1465970   2.083333  0.000000    2.866667    2.700000    29.000000   0.000000   \n",
       "1567359   1.391369  0.019545   -0.566667    2.531482    15.633042   0.020608   \n",
       "1603119  10.883333  0.066667    1.883333    9.300000    19.000000   0.095238   \n",
       "1536619   3.516667  0.125000    2.016667    5.600000     9.000000   0.000000   \n",
       "1455481   8.383333  0.000000    7.083333   10.733333     4.000000   0.000000   \n",
       "...            ...       ...         ...         ...          ...        ...   \n",
       "1428786   2.016667  0.000000   -5.342989    0.366667    15.633042   0.020608   \n",
       "1547718   5.966667  0.040000   12.500000    7.200000    92.000000   0.000000   \n",
       "1354914   3.650000  0.000000    0.066667    2.531482    15.633042   0.020608   \n",
       "778010    0.416667  0.000000    6.800000    2.531482    11.000000   0.000000   \n",
       "1575451  20.700000  0.000000   -2.366667   24.733333    24.000000   0.040000   \n",
       "\n",
       "         预测值  标签  \n",
       "1465970    0   1  \n",
       "1567359    0   1  \n",
       "1603119    0   1  \n",
       "1536619    0   1  \n",
       "1455481    0   1  \n",
       "...      ...  ..  \n",
       "1428786    0   1  \n",
       "1547718    0   1  \n",
       "1354914    0   1  \n",
       "778010     1   0  \n",
       "1575451    0   1  \n",
       "\n",
       "[30140 rows x 37 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#重新构造测试数据\n",
    "test['预测值'] = preds\n",
    "test['标签'] = test_labels\n",
    "dataError = test[test['标签'] != test['预测值']]\n",
    "dataError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataError = dataError.sample(n=15000,replace=False, random_state=None,axis=0)\n",
    "dataTrue = test[test['标签'] == test['预测值']]\n",
    "dataTrue1= dataTrue[dataTrue['标签']==1]\n",
    "\n",
    "dataTrue1 = dataTrue.sample(n=15140,replace=False, random_state=None,axis=0)\n",
    "dataTrue =pd.concat([dataTrue, dataTrue1], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_new = pd.concat([dataTrue, dataError], axis=0, ignore_index=True)\n",
    "test_labels_new = np.array(test_data_new['标签'].astype(np.int32)).reshape((-1,))\n",
    "test_data_new = test_data_new.drop(['预测值','标签'],axis=1)\n",
    "test_features_new = np.array(test_data_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97    225699\n",
      "           1       0.90      0.96      0.93     97404\n",
      "\n",
      "    accuracy                           0.95    323103\n",
      "   macro avg       0.94      0.95      0.95    323103\n",
      "weighted avg       0.96      0.95      0.95    323103\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds_new = best_bayes_model.predict(test_features_new)\n",
    "from sklearn.metrics import classification_report \n",
    "test_labels_new = test_labels_new.tolist()\n",
    "test_labels_new = np.array([i for i in test_labels_new])\n",
    "print(classification_report(preds_new, test_labels_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "验证样本的准确率: 0.9536\n",
      "('ks', 0.7642466998059849)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "testAccuracy = metrics.accuracy_score(test_labels_new, preds_new)\n",
    "print(\"验证样本的准确率: %.4f\" % testAccuracy)\n",
    "print(ks_score) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
