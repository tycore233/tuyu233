{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>航班编号</th>\n",
       "      <th>计划起飞时间</th>\n",
       "      <th>计划到达时间</th>\n",
       "      <th>计划起飞时刻</th>\n",
       "      <th>计划到达时刻</th>\n",
       "      <th>计划飞行时间</th>\n",
       "      <th>起飞间隔</th>\n",
       "      <th>前序延误</th>\n",
       "      <th>平均延误时间</th>\n",
       "      <th>最大延误时间</th>\n",
       "      <th>...</th>\n",
       "      <th>本时段实际进港延误航班数</th>\n",
       "      <th>本时段离港延误时长</th>\n",
       "      <th>本时段离港平均延误时长</th>\n",
       "      <th>本时段离港延误率</th>\n",
       "      <th>上一时段离港平均延误时长</th>\n",
       "      <th>上一时段进港延误时长</th>\n",
       "      <th>上一时段离港延误时长</th>\n",
       "      <th>上一时段实际进港航班数</th>\n",
       "      <th>上一时段进港延误率</th>\n",
       "      <th>标签</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CZ3855</td>\n",
       "      <td>16801</td>\n",
       "      <td>16801</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.963379</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CZ3855</td>\n",
       "      <td>16801</td>\n",
       "      <td>16801</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.963379</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CZ3855</td>\n",
       "      <td>16801</td>\n",
       "      <td>16801</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.963379</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CZ3855</td>\n",
       "      <td>16801</td>\n",
       "      <td>16801</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.963379</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CZ3295</td>\n",
       "      <td>16801</td>\n",
       "      <td>16801</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.324175</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     航班编号  计划起飞时间  计划到达时间  计划起飞时刻  计划到达时刻    计划飞行时间  起飞间隔  前序延误    平均延误时间  \\\n",
       "0  CZ3855   16801   16801       0       3  3.666667   NaN   NaN  1.963379   \n",
       "1  CZ3855   16801   16801       0       3  3.666667   NaN   NaN  1.963379   \n",
       "2  CZ3855   16801   16801       0       1  1.250000   NaN   NaN  1.963379   \n",
       "3  CZ3855   16801   16801       0       1  1.250000   NaN   NaN  1.963379   \n",
       "4  CZ3295   16801   16801       0       1  1.166667   NaN   NaN  0.324175   \n",
       "\n",
       "   最大延误时间 ...  本时段实际进港延误航班数  本时段离港延误时长  本时段离港平均延误时长  本时段离港延误率  上一时段离港平均延误时长  \\\n",
       "0    10.0 ...           NaN        NaN          NaN       NaN           NaN   \n",
       "1    10.0 ...           NaN        NaN          NaN       NaN           NaN   \n",
       "2    10.0 ...           NaN        NaN          NaN       NaN           NaN   \n",
       "3    10.0 ...           NaN        NaN          NaN       NaN           NaN   \n",
       "4    10.0 ...           NaN        NaN          NaN       NaN           NaN   \n",
       "\n",
       "   上一时段进港延误时长  上一时段离港延误时长  上一时段实际进港航班数  上一时段进港延误率  标签  \n",
       "0         NaN         NaN          NaN        NaN   1  \n",
       "1         NaN         NaN          NaN        NaN   1  \n",
       "2         NaN         NaN          NaN        NaN   1  \n",
       "3         NaN         NaN          NaN        NaN   1  \n",
       "4         NaN         NaN          NaN        NaN   1  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['font.serif'] = ['SimHei']\n",
    "\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "p = sns.color_palette()\n",
    "sns.set_style(\"darkgrid\",{\"font.sans-serif\":['simhei', 'Arial']})\n",
    "\n",
    "# 航班数据\n",
    "feature = pd.read_table('/Users/tuyu/000000毕业设计/Flight_Delay/Train_Feature/final_feature.csv',sep=',',encoding='gb2312')\n",
    "feature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature0 = feature[feature['标签'] == 0]\n",
    "feature0new = feature0.sample(frac=0.15, replace=False, random_state=None,axis=0)\n",
    "feature1 = feature[feature['标签'] == 1]\n",
    "featureGBDT = pd.concat([feature0new,feature1],axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature0SVM = feature0new.sample(frac=0.15, replace=False, random_state=None,axis=0)\n",
    "feature1SVM = feature1.sample(frac=0.15, replace=False, random_state=None,axis=0)\n",
    "featureSVM = pd.concat([feature0SVM,feature1SVM],axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del(featureGBDT['本时段离港平均延误时长'])\n",
    "del(featureGBDT['上一时段离港平均延误时长'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1.前序延误 = 前序航班 实际到达时间 - 计划到达时间\n",
    "# 2.起飞间隔 = 当前航班的计划起飞时间 - 前序航班实际到达时间\n",
    "featureGBDT['起飞间隔'] = featureGBDT['起飞间隔'].fillna(0)\n",
    "featureGBDT['前序延误'] = featureGBDT['前序延误'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featureGBDT['出发机场天气得分'] = featureGBDT['出发机场天气得分'].interpolate()\n",
    "featureGBDT['到达机场天气得分'] = featureGBDT['到达机场天气得分'].interpolate()\n",
    "featureGBDT['平均延误时间'] = featureGBDT['平均延误时间'].interpolate()\n",
    "featureGBDT['最大延误时间'] = featureGBDT['最大延误时间'].interpolate()\n",
    "featureGBDT['延误时间中位数'] = featureGBDT['延误时间中位数'].interpolate()\n",
    "featureGBDT['延误时间标准差'] = featureGBDT['延误时间标准差'].interpolate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "featureGBDT['本时段计划离港航班数'] = featureGBDT['本时段计划离港航班数'].fillna(featureGBDT['本时段计划离港航班数'].mean())\n",
    "featureGBDT['本时段实际离港航班数'] = featureGBDT['本时段实际离港航班数'].fillna(featureGBDT['本时段实际离港航班数'].mean())\n",
    "featureGBDT['本时段进港延误时长'] = featureGBDT['本时段进港延误时长'].fillna(featureGBDT['本时段进港延误时长'].mean())\n",
    "featureGBDT['本时段实际进港延误航班数'] = featureGBDT['本时段实际进港延误航班数'].fillna(featureGBDT['本时段实际进港延误航班数'].mean())\n",
    "featureGBDT['本时段离港延误时长'] = featureGBDT['本时段离港延误时长'].fillna(featureGBDT['本时段离港延误时长'].mean())\n",
    "featureGBDT['本时段离港延误率'] = featureGBDT['本时段离港延误率'].fillna(featureGBDT['本时段离港延误率'].mean())\n",
    "featureGBDT['上一时段进港延误时长'] = featureGBDT['上一时段进港延误时长'].fillna(featureGBDT['上一时段进港延误时长'].mean())\n",
    "featureGBDT['上一时段离港延误时长'] = featureGBDT['上一时段离港延误时长'].fillna(featureGBDT['上一时段离港延误时长'].mean())\n",
    "featureGBDT['上一时段实际进港航班数'] = featureGBDT['上一时段实际进港航班数'].fillna(featureGBDT['上一时段实际进港航班数'].mean())\n",
    "featureGBDT['上一时段进港延误率'] = featureGBDT['上一时段进港延误率'].fillna(featureGBDT['上一时段进港延误率'].mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del(featureSVM['本时段离港平均延误时长'])\n",
    "del(featureSVM['上一时段离港平均延误时长'])\n",
    "# 1.前序延误 = 前序航班 实际到达时间 - 计划到达时间\n",
    "# 2.起飞间隔 = 当前航班的计划起飞时间 - 前序航班实际到达时间\n",
    "featureSVM['起飞间隔'] = featureSVM['起飞间隔'].fillna(0)\n",
    "featureSVM['前序延误'] = featureSVM['前序延误'].fillna(0)\n",
    "featureSVM['出发机场天气得分'] = featureSVM['出发机场天气得分'].interpolate()\n",
    "featureSVM['到达机场天气得分'] = featureSVM['到达机场天气得分'].interpolate()\n",
    "featureSVM['平均延误时间'] = featureSVM['平均延误时间'].interpolate()\n",
    "featureSVM['最大延误时间'] = featureSVM['最大延误时间'].interpolate()\n",
    "featureSVM['延误时间中位数'] = featureSVM['延误时间中位数'].interpolate()\n",
    "featureSVM['延误时间标准差'] = featureSVM['延误时间标准差'].interpolate()\n",
    "featureSVM['本时段计划离港航班数'] = featureSVM['本时段计划离港航班数'].fillna(featureSVM['本时段计划离港航班数'].mean())\n",
    "featureSVM['本时段实际离港航班数'] = featureSVM['本时段实际离港航班数'].fillna(featureSVM['本时段实际离港航班数'].mean())\n",
    "featureSVM['本时段进港延误时长'] = featureSVM['本时段进港延误时长'].fillna(featureSVM['本时段进港延误时长'].mean())\n",
    "featureSVM['本时段实际进港延误航班数'] = featureSVM['本时段实际进港延误航班数'].fillna(featureSVM['本时段实际进港延误航班数'].mean())\n",
    "featureSVM['本时段离港延误时长'] = featureSVM['本时段离港延误时长'].fillna(featureSVM['本时段离港延误时长'].mean())\n",
    "featureSVM['本时段离港延误率'] = featureSVM['本时段离港延误率'].fillna(featureSVM['本时段离港延误率'].mean())\n",
    "featureSVM['上一时段进港延误时长'] = featureSVM['上一时段进港延误时长'].fillna(featureSVM['上一时段进港延误时长'].mean())\n",
    "featureSVM['上一时段离港延误时长'] = featureSVM['上一时段离港延误时长'].fillna(featureSVM['上一时段离港延误时长'].mean())\n",
    "featureSVM['上一时段实际进港航班数'] = featureSVM['上一时段实际进港航班数'].fillna(featureSVM['上一时段实际进港航班数'].mean())\n",
    "featureSVM['上一时段进港延误率'] = featureSVM['上一时段进港延误率'].fillna(featureSVM['上一时段进港延误率'].mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del(feature['本时段离港平均延误时长'])\n",
    "del(feature['上一时段离港平均延误时长'])\n",
    "# 1.前序延误 = 前序航班 实际到达时间 - 计划到达时间\n",
    "# 2.起飞间隔 = 当前航班的计划起飞时间 - 前序航班实际到达时间\n",
    "feature['起飞间隔'] = feature['起飞间隔'].fillna(0)\n",
    "feature['前序延误'] = feature['前序延误'].fillna(0)\n",
    "feature['出发机场天气得分'] = feature['出发机场天气得分'].interpolate()\n",
    "feature['到达机场天气得分'] = feature['到达机场天气得分'].interpolate()\n",
    "feature['平均延误时间'] = feature['平均延误时间'].interpolate()\n",
    "feature['最大延误时间'] = feature['最大延误时间'].interpolate()\n",
    "feature['延误时间中位数'] = feature['延误时间中位数'].interpolate()\n",
    "feature['延误时间标准差'] = feature['延误时间标准差'].interpolate()\n",
    "\n",
    "feature['本时段计划离港航班数'] = feature['本时段计划离港航班数'].fillna(feature['本时段计划离港航班数'].mean())\n",
    "feature['本时段实际离港航班数'] = feature['本时段实际离港航班数'].fillna(feature['本时段实际离港航班数'].mean())\n",
    "feature['本时段进港延误时长'] = feature['本时段进港延误时长'].fillna(feature['本时段进港延误时长'].mean())\n",
    "feature['本时段实际进港延误航班数'] = feature['本时段实际进港延误航班数'].fillna(feature['本时段实际进港延误航班数'].mean())\n",
    "feature['本时段离港延误时长'] = feature['本时段离港延误时长'].fillna(feature['本时段离港延误时长'].mean())\n",
    "feature['本时段离港延误率'] = feature['本时段离港延误率'].fillna(feature['本时段离港延误率'].mean())\n",
    "feature['上一时段进港延误时长'] = feature['上一时段进港延误时长'].fillna(feature['上一时段进港延误时长'].mean())\n",
    "feature['上一时段离港延误时长'] = feature['上一时段离港延误时长'].fillna(feature['上一时段离港延误时长'].mean())\n",
    "feature['上一时段实际进港航班数'] = feature['上一时段实际进港航班数'].fillna(feature['上一时段实际进港航班数'].mean())\n",
    "feature['上一时段进港延误率'] = feature['上一时段进港延误率'].fillna(feature['上一时段进港延误率'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "def ks(y_predicted, y_true):\n",
    "    label=y_true\n",
    "    #label = y_true.get_label()\n",
    "    fpr,tpr,thres = metrics.roc_curve(label,y_predicted,pos_label=1)\n",
    "    return 'ks',abs(fpr - tpr).max()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBOOST模型评估\n",
      "训练样本的准确率: 0.9750\n",
      "average_precision: 0.6820\n",
      "查准率: 0.9154\n",
      "召回率: 0.7230\n",
      "F1-Score: 0.8079\n",
      "AUC-Score_predprob: 0.9740\n",
      "验证样本的准确率: 0.9698\n",
      "查准率: 0.8694\n",
      "召回率: 0.6850\n",
      "F1-Score: 0.7663\n",
      "AUC-Score: 0.9583\n",
      "('ks', 0.6769884140022178)\n"
     ]
    }
   ],
   "source": [
    "#XGBOOST模型调参,测试样本0.3，训练集占0.7，模型效果为：\n",
    "# XGBOOST模型评估\n",
    "# 训练样本的准确率: 0.9724\n",
    "# average_precision: 0.6494\n",
    "# 查准率: 0.8938\n",
    "# 召回率: 0.7025\n",
    "# F1-Score: 0.7866\n",
    "# AUC-Score_predprob: 0.9670\n",
    "# 验证样本的准确率: 0.9707\n",
    "# 查准率: 0.8790\n",
    "# 召回率: 0.6891\n",
    "# F1-Score: 0.7726\n",
    "# AUC-Score: 0.9606\n",
    "# ('ks', 0.6817467680926879)\n",
    "\n",
    "\n",
    "\n",
    "#XGBOOST模型调参,测试样本0.1，训练集占0.9，模型效果为：\n",
    "# XGBOOST模型评估\n",
    "# 训练样本的准确率: 0.9718\n",
    "# average_precision: 0.6414\n",
    "# 查准率: 0.8901\n",
    "# 召回率: 0.6960\n",
    "# F1-Score: 0.7811\n",
    "# AUC-Score_predprob: 0.9639\n",
    "# 验证样本的准确率: 0.9710\n",
    "# 查准率: 0.8856\n",
    "# 召回率: 0.6887\n",
    "# F1-Score: 0.7748\n",
    "# AUC-Score: 0.9609\n",
    "# ('ks', 0.6817358342785097)\n",
    "\n",
    "from numpy import loadtxt,sort\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy\n",
    "\n",
    "dataset = feature.as_matrix()\n",
    "X = dataset[:,1:36]\n",
    "Y = dataset[:,36]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.9, random_state=7)\n",
    "import numpy as np\n",
    "\n",
    "# # # fit model on all training data\n",
    "xgboost = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27,\n",
    " tree_method='gpu_hist')\n",
    "\n",
    "\n",
    "xgboost_model = xgboost.fit(x_train, y_train.astype('int'))\n",
    "\n",
    "\n",
    "# 利用训练的模型来测试  训练集\n",
    "prediction_train = xgboost_model.predict(x_train)\n",
    "prediction_train_predprob = xgboost_model.predict_proba(x_train)[:,1]\n",
    " \n",
    "# #利用训练的模型来测试  验证集集\n",
    "prediction_test = xgboost_model.predict(x_test)\n",
    "prediction_test_predprob = xgboost_model.predict_proba(x_test)[:,1]\n",
    "\n",
    "prediction_test = prediction_test.tolist()\n",
    "y_test = y_test.tolist()\n",
    "prediction_test = np.array(prediction_test)\n",
    "y_test = np.array([i for i in y_test])\n",
    "\n",
    "y_train = y_train.tolist()\n",
    "y_train = np.array([i for i in y_train])\n",
    "\n",
    "prediction_train = prediction_train.tolist()\n",
    "prediction_train = np.array(prediction_train)\n",
    "\n",
    "# y_pred = gbdt_model.predict(x_test)\n",
    "# y_pred = y_pred.tolist()\n",
    "# y_test = y_test.tolist()\n",
    "# y_pred = np.array(y_pred)\n",
    "# y_test = np.array([i for i in y_test])\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(\"XGBOOST模型评估\")\n",
    "testAccuracy = metrics.accuracy_score(y_train, prediction_train)\n",
    "print(\"训练样本的准确率: %.4f\" % testAccuracy)\n",
    " \n",
    "average_precision = metrics.average_precision_score(y_train, prediction_train)\n",
    "print(\"average_precision: %.4f\" % average_precision)\n",
    " \n",
    "#查准率\n",
    "averagePrecisionScore = metrics.precision_score(y_train, prediction_train)\n",
    "print(\"查准率: %.4f\" % averagePrecisionScore)\n",
    " \n",
    "##召回率\n",
    "returnResultScore = metrics.recall_score(y_train, prediction_train)\n",
    "print(\"召回率: %.4f\" % returnResultScore)\n",
    " \n",
    "##F1值\n",
    "F1Score = metrics.f1_score(y_train, prediction_train)\n",
    "print(\"F1-Score: %.4f\" % F1Score)\n",
    " \n",
    "#计算auc\n",
    "roc_auc_predprob = metrics.roc_auc_score(y_train, prediction_train_predprob)\n",
    "print(\"AUC-Score_predprob: %.4f\" % roc_auc_predprob)\n",
    " \n",
    "\n",
    "testAccuracy = metrics.accuracy_score(y_test, prediction_test)\n",
    "print(\"验证样本的准确率: %.4f\" % testAccuracy)\n",
    " \n",
    "#查准率\n",
    "averagePrecisionScore = metrics.precision_score(y_test, prediction_test)\n",
    "print(\"查准率: %.4f\" % averagePrecisionScore)\n",
    " \n",
    "##召回率\n",
    "returnResultScore = metrics.recall_score(y_test, prediction_test)\n",
    "print(\"召回率: %.4f\" % returnResultScore)\n",
    " \n",
    "##F1值\n",
    "F1Score = metrics.f1_score(y_test, prediction_test)\n",
    "print(\"F1-Score: %.4f\" % F1Score)\n",
    " \n",
    "#计算auc\n",
    "roc_auc = metrics.roc_auc_score(y_test, prediction_test_predprob)\n",
    "print(\"AUC-Score: %.4f\" % roc_auc)\n",
    "\n",
    "ks_score = ks(prediction_test, y_test)\n",
    "print(ks_score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report \n",
    "print(\"XGBOOST模型评估\")\n",
    "print(classification_report(prediction_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "f= open('/Users/tuyu/000000毕业设计/Flight_Delay/Model/model/xgboost_model.pickle','wb')\n",
    "pickle.dump(xgboost_model,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from numpy import loadtxt,sort\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy\n",
    "\n",
    "with open('/Users/tuyu/000000毕业设计/Flight_Delay/Model/model/xgboost_model.pickle','rb') as fr:\n",
    "    xgboost_model = pickle.load(fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tuyu/Library/Python/3.6/lib/python/site-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "dataset = feature.as_matrix()\n",
    "X = dataset[:,1:36]\n",
    "Y = dataset[:,36]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_offline = xgboost_model.predict(x_test)\n",
    "preds_offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01961278, 0.0017142 , 0.00281581, ..., 0.00516581, 0.00811391,\n",
       "       0.00312906], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_test_predprob = xgboost_model.predict_proba(x_test)[:,1]\n",
    "prediction_test_predprob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "offline=(prediction_test_predprob >= 0.4) *1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 利用训练的模型来测试  训练集\n",
    "prediction_train = xgboost_model.predict(x_train)\n",
    "prediction_train_predprob = xgboost_model.predict_proba(x_train)[:,1]\n",
    " \n",
    "# #利用训练的模型来测试  验证集集\n",
    "prediction_test = xgboost_model.predict(x_test)\n",
    "prediction_test_predprob = xgboost_model.predict_proba(x_test)[:,1]\n",
    "\n",
    "prediction_test = prediction_test.tolist()\n",
    "y_test = y_test.tolist()\n",
    "prediction_test = np.array(prediction_test)\n",
    "y_test = np.array([i for i in y_test])\n",
    "\n",
    "y_train = y_train.tolist()\n",
    "y_train = np.array([i for i in y_train])\n",
    "\n",
    "prediction_train = prediction_train.tolist()\n",
    "prediction_train = np.array(prediction_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8477633309393451"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#召回率\n",
    "returnResultScore = metrics.recall_score(offline, y_test)\n",
    "returnResultScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98   6445888\n",
      "           1       0.73      0.85      0.79    428852\n",
      "\n",
      "    accuracy                           0.97   6874740\n",
      "   macro avg       0.86      0.91      0.88   6874740\n",
      "weighted avg       0.97      0.97      0.97   6874740\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report \n",
    "print(classification_report(offline, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.2742           0.0110            2.06m\n",
      "         2           1.2668           0.0077            1.98m\n",
      "         3           1.2607           0.0054            1.98m\n",
      "         4           1.2514           0.0090            1.97m\n",
      "         5           1.2467           0.0047            1.92m\n",
      "         6           1.2423           0.0056            1.89m\n",
      "         7           1.2303           0.0109            1.86m\n",
      "         8           1.2218           0.0087            1.83m\n",
      "         9           1.2149           0.0073            1.81m\n",
      "        10           1.2069           0.0084            1.79m\n",
      "        11           1.1997           0.0066            1.76m\n",
      "        12           1.1904           0.0093            1.74m\n",
      "        13           1.1847           0.0056            1.71m\n",
      "        14           1.1790           0.0064            1.69m\n",
      "        15           1.1689           0.0091            1.67m\n",
      "        16           1.1616           0.0083            1.65m\n",
      "        17           1.1582           0.0030            1.62m\n",
      "        18           1.1507           0.0073            1.58m\n",
      "        19           1.1437           0.0067            1.55m\n",
      "        20           1.1362           0.0076            1.53m\n",
      "        21           1.1273           0.0086            1.50m\n",
      "        22           1.1233           0.0046            1.48m\n",
      "        23           1.1185           0.0051            1.45m\n",
      "        24           1.1112           0.0072            1.43m\n",
      "        25           1.1066           0.0050            1.40m\n",
      "        26           1.1017           0.0039            1.38m\n",
      "        27           1.0943           0.0078            1.35m\n",
      "        28           1.0922           0.0020            1.33m\n",
      "        29           1.0852           0.0070            1.30m\n",
      "        30           1.0781           0.0072            1.28m\n",
      "        31           1.0718           0.0060            1.25m\n",
      "        32           1.0684           0.0031            1.23m\n",
      "        33           1.0636           0.0052            1.20m\n",
      "        34           1.0595           0.0041            1.18m\n",
      "        35           1.0557           0.0041            1.15m\n",
      "        36           1.0482           0.0073            1.12m\n",
      "        37           1.0456           0.0030            1.10m\n",
      "        38           1.0386           0.0066            1.07m\n",
      "        39           1.0317           0.0071            1.05m\n",
      "        40           1.0255           0.0057            1.02m\n",
      "        41           1.0209           0.0049           59.88s\n",
      "        42           1.0153           0.0058           58.40s\n",
      "        43           1.0116           0.0041           56.82s\n",
      "        44           1.0062           0.0053           55.40s\n",
      "        45           1.0037           0.0027           53.86s\n",
      "        46           0.9983           0.0044           52.36s\n",
      "        47           0.9947           0.0040           50.75s\n",
      "        48           0.9900           0.0052           49.20s\n",
      "        49           0.9860           0.0037           47.70s\n",
      "        50           0.9797           0.0056           46.21s\n",
      "        51           0.9777           0.0027           44.62s\n",
      "        52           0.9725           0.0052           43.05s\n",
      "        53           0.9667           0.0053           41.53s\n",
      "        54           0.9620           0.0054           40.00s\n",
      "        55           0.9609           0.0014           38.48s\n",
      "        56           0.9563           0.0036           36.98s\n",
      "        57           0.9524           0.0046           35.44s\n",
      "        58           0.9484           0.0043           33.92s\n",
      "        59           0.9432           0.0046           32.37s\n",
      "        60           0.9378           0.0051           30.85s\n",
      "        61           0.9330           0.0046           29.29s\n",
      "        62           0.9307           0.0028           27.72s\n",
      "        63           0.9258           0.0047           26.16s\n",
      "        64           0.9221           0.0040           24.61s\n",
      "        65           0.9178           0.0042           23.08s\n",
      "        66           0.9144           0.0028           21.54s\n",
      "        67           0.9109           0.0041           20.00s\n",
      "        68           0.9054           0.0045           18.48s\n",
      "        69           0.9025           0.0035           16.93s\n",
      "        70           0.8990           0.0040           15.38s\n",
      "        71           0.8943           0.0040           13.84s\n",
      "        72           0.8906           0.0040           12.30s\n",
      "        73           0.8868           0.0039           10.76s\n",
      "        74           0.8822           0.0040            9.23s\n",
      "        75           0.8796           0.0028            7.69s\n",
      "        76           0.8771           0.0037            6.15s\n",
      "        77           0.8727           0.0038            4.61s\n",
      "        78           0.8716           0.0017            3.08s\n",
      "        79           0.8666           0.0040            1.54s\n",
      "        80           0.8647           0.0027            0.00s\n",
      "欠采样下GBDT模型评估\n",
      "训练样本的准确率: 0.8718\n",
      "average_precision: 0.7401\n",
      "查准率: 0.9316\n",
      "召回率: 0.6751\n",
      "F1-Score: 0.7829\n",
      "AUC-Score_predprob: 0.9324\n",
      "验证样本的准确率: 0.8727\n",
      "查准率: 0.9321\n",
      "召回率: 0.6761\n",
      "F1-Score: 0.7837\n",
      "AUC-Score: 0.9329\n",
      "('ks', 0.6506359841349884)\n"
     ]
    }
   ],
   "source": [
    "#欠采样下GBDT模型准确率\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier   #分类模型\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "dataset=featureGBDT.as_matrix()\n",
    "X = dataset[:,1:36]\n",
    "Y = dataset[:,36]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=7)\n",
    "\n",
    "gbdt = GradientBoostingClassifier(\n",
    "    loss='deviance',\n",
    "    learning_rate=0.01, #学习速率\n",
    "    n_estimators=500,    #训练迭代次数\n",
    "    subsample=0.6,      #每次训练随机抽取的样本集大小为60%\n",
    "    max_features= 'sqrt',\n",
    "    max_depth=6,\n",
    "    verbose = 2\n",
    ")\n",
    "\n",
    "gbdt_model = gbdt.fit(x_train, y_train.astype('int'))  #模型训练开始\n",
    "\n",
    "#特征值权重排序\n",
    "#feat_labels = x_train.columns[2:]   #特征列名\n",
    "# importances = gbdt_model.feature_importances_          #feature_importances_特征列重要性占比\n",
    "# indices = np.argsort(importances)[::-1]               #对参数从小到大排序的索引序号取逆,即最重要特征索引——>最不重要特征索引\n",
    "# print(indices)\n",
    "# print(len(indices))\n",
    " \n",
    "# for f in range(len(indices)):\n",
    "#     print(\"%2d) %-*s %f\" % (f, 30, indices[f], importances[indices[f]]))\n",
    "\n",
    "#利用训练的模型来测试  训练集\n",
    "prediction_train = gbdt_model.predict(x_train)\n",
    "prediction_train_predprob = gbdt_model.predict_proba(x_train)[:,1]\n",
    " \n",
    "# #利用训练的模型来测试  验证集集\n",
    "prediction_test = gbdt_model.predict(x_test)\n",
    "prediction_test_predprob = gbdt_model.predict_proba(x_test)[:,1]\n",
    "\n",
    "\n",
    "\n",
    "prediction_test = prediction_test.tolist()\n",
    "y_test = y_test.tolist()\n",
    "prediction_test = np.array(prediction_test)\n",
    "y_test = np.array([i for i in y_test])\n",
    "\n",
    "y_train = y_train.tolist()\n",
    "y_train = np.array([i for i in y_train])\n",
    "\n",
    "prediction_train = prediction_train.tolist()\n",
    "prediction_train = np.array(prediction_train)\n",
    "\n",
    "\n",
    "print(\"欠采样下GBDT模型评估\")\n",
    "testAccuracy = metrics.accuracy_score(y_train, prediction_train)\n",
    "print(\"训练样本的准确率: %.4f\" % testAccuracy)\n",
    " \n",
    "average_precision = metrics.average_precision_score(y_train, prediction_train)\n",
    "print(\"average_precision: %.4f\" % average_precision)\n",
    " \n",
    "#查准率\n",
    "averagePrecisionScore = metrics.precision_score(y_train, prediction_train)\n",
    "print(\"查准率: %.4f\" % averagePrecisionScore)\n",
    " \n",
    "##召回率\n",
    "returnResultScore = metrics.recall_score(y_train, prediction_train)\n",
    "print(\"召回率: %.4f\" % returnResultScore)\n",
    " \n",
    "##F1值\n",
    "F1Score = metrics.f1_score(y_train, prediction_train)\n",
    "print(\"F1-Score: %.4f\" % F1Score)\n",
    " \n",
    "#计算auc\n",
    "roc_auc_predprob = metrics.roc_auc_score(y_train, prediction_train_predprob)\n",
    "print(\"AUC-Score_predprob: %.4f\" % roc_auc_predprob)\n",
    " \n",
    "\n",
    "testAccuracy = metrics.accuracy_score(y_test, prediction_test)\n",
    "print(\"验证样本的准确率: %.4f\" % testAccuracy)\n",
    " \n",
    "#查准率\n",
    "averagePrecisionScore = metrics.precision_score(y_test, prediction_test)\n",
    "print(\"查准率: %.4f\" % averagePrecisionScore)\n",
    " \n",
    "##召回率\n",
    "returnResultScore = metrics.recall_score(y_test, prediction_test)\n",
    "print(\"召回率: %.4f\" % returnResultScore)\n",
    " \n",
    "##F1值\n",
    "F1Score = metrics.f1_score(y_test, prediction_test)\n",
    "print(\"F1-Score: %.4f\" % F1Score)\n",
    " \n",
    "#计算auc\n",
    "roc_auc = metrics.roc_auc_score(y_test, prediction_test_predprob)\n",
    "print(\"AUC-Score: %.4f\" % roc_auc)\n",
    "\n",
    "\n",
    "ks_score = ks(prediction_test, y_test)\n",
    "print( ks_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f= open('/Users/tuyu/000000毕业设计/Flight_Delay/Model/model/gbdt_model.pickle','wb')\n",
    "pickle.dump(gbdt_model,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/Users/tuyu/000000毕业设计/Flight_Delay/Model/model/gbdt_model.pickle','rb') as fr:\n",
    "    gbdt_model = pickle.load(fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tuyu/Library/Python/3.6/lib/python/site-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "datasetGBDT = featureGBDT.as_matrix()\n",
    "X = datasetGBDT[:,1:36]\n",
    "Y = datasetGBDT[:,36]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 0, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_offline = gbdt_model.predict(x_test)\n",
    "preds_offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2126644 , 0.5576149 , 0.63646062, ..., 0.21015275, 0.20467959,\n",
       "       0.48167739])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_test_predprob = gbdt_model.predict_proba(x_test)[:,1]\n",
    "prediction_test_predprob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323103\n",
      "79988\n"
     ]
    }
   ],
   "source": [
    "print(len(prediction_test_predprob))\n",
    "print(sum(prediction_test_predprob >= 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbdt_offline=(prediction_test_predprob >= 0.4) *1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "y_test = y_test.tolist()\n",
    "y_test = np.array([i for i in y_test])\n",
    "\n",
    "y_train = y_train.tolist()\n",
    "y_train = np.array([i for i in y_train])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8439040389841627"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#召回率\n",
    "returnResultScore = metrics.recall_score(gbdt_offline, y_test)\n",
    "returnResultScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91    216393\n",
      "           1       0.82      0.84      0.83    106710\n",
      "\n",
      "    accuracy                           0.89    323103\n",
      "   macro avg       0.87      0.88      0.87    323103\n",
      "weighted avg       0.89      0.89      0.89    323103\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report \n",
    "print(classification_report(gbdt_offline, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "LightGBM模型结果\n",
      "训练样本的准确率: 0.9247\n",
      "average_precision: 0.4300\n",
      "查准率: 0.4887\n",
      "召回率: 0.8589\n",
      "F1-Score: 0.6229\n",
      "AUC-Score_predprob: 0.9549\n",
      "验证样本的准确率: 0.9244\n",
      "查准率: 0.4865\n",
      "召回率: 0.8562\n",
      "F1-Score: 0.6205\n",
      "AUC-Score: 0.9534\n",
      "('ks', 0.7858976068609829)\n"
     ]
    }
   ],
   "source": [
    "#LGBM模型结果\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = feature.as_matrix()\n",
    "X = dataset[:,1:36]\n",
    "Y = dataset[:,36]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=7)\n",
    "\n",
    "\n",
    "model = lgb.LGBMClassifier(\n",
    "        boosting_type = 'gbdt',\n",
    "        boosting = 'dart',\n",
    "        learning_rate= 0.3,\n",
    "        num_leaves = 25,\n",
    "        max_depth=15,\n",
    "        min_data_in_leaf= 25,\n",
    "        feature_fraction= 0.8,\n",
    "        bagging_fraction= 1,\n",
    "        bagging_freq= 1,\n",
    "        lambda_l1= 1,\n",
    "        lambda_l2= 1,\n",
    "        min_split_gain=0.5,\n",
    "        objective= 'binary',\n",
    "        metric= 'auc',\n",
    "        is_unbalance=True\n",
    "    )\n",
    "\n",
    "\n",
    "lgb_model = model.fit(x_train,  # 训练集\n",
    "                      y_train.astype('int'))  # 早停系数\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#利用训练的模型来测试  训练集\n",
    "prediction_train = lgb_model.predict(x_train)\n",
    "prediction_train_predprob = lgb_model.predict_proba(x_train)[:,1]\n",
    " \n",
    "# #利用训练的模型来测试  验证集集\n",
    "prediction_test = lgb_model.predict(x_test)\n",
    "prediction_test_predprob = lgb_model.predict_proba(x_test)[:,1]\n",
    "\n",
    "prediction_test = prediction_test.tolist()\n",
    "y_test = y_test.tolist()\n",
    "prediction_test = np.array(prediction_test)\n",
    "y_test = np.array([i for i in y_test])\n",
    "\n",
    "y_train = y_train.tolist()\n",
    "y_train = np.array([i for i in y_train])\n",
    "\n",
    "prediction_train = prediction_train.tolist()\n",
    "prediction_train = np.array(prediction_train)\n",
    "\n",
    "\n",
    "print(\"LightGBM模型结果\")\n",
    "\n",
    "testAccuracy = metrics.accuracy_score(y_train, prediction_train)\n",
    "print(\"训练样本的准确率: %.4f\" % testAccuracy)\n",
    " \n",
    "average_precision = metrics.average_precision_score(y_train, prediction_train)\n",
    "print(\"average_precision: %.4f\" % average_precision)\n",
    " \n",
    "#查准率\n",
    "averagePrecisionScore = metrics.precision_score(y_train, prediction_train)\n",
    "print(\"查准率: %.4f\" % averagePrecisionScore)\n",
    " \n",
    "##召回率\n",
    "returnResultScore = metrics.recall_score(y_train, prediction_train)\n",
    "print(\"召回率: %.4f\" % returnResultScore)\n",
    " \n",
    "##F1值\n",
    "F1Score = metrics.f1_score(y_train, prediction_train)\n",
    "print(\"F1-Score: %.4f\" % F1Score)\n",
    " \n",
    "#计算auc\n",
    "roc_auc_predprob = metrics.roc_auc_score(y_train, prediction_train_predprob)\n",
    "print(\"AUC-Score_predprob: %.4f\" % roc_auc_predprob)\n",
    " \n",
    "\n",
    "testAccuracy = metrics.accuracy_score(y_test, prediction_test)\n",
    "print(\"验证样本的准确率: %.4f\" % testAccuracy)\n",
    " \n",
    "#查准率\n",
    "averagePrecisionScore = metrics.precision_score(y_test, prediction_test)\n",
    "print(\"查准率: %.4f\" % averagePrecisionScore)\n",
    " \n",
    "##召回率\n",
    "returnResultScore = metrics.recall_score(y_test, prediction_test)\n",
    "print(\"召回率: %.4f\" % returnResultScore)\n",
    " \n",
    "##F1值\n",
    "F1Score = metrics.f1_score(y_test, prediction_test)\n",
    "print(\"F1-Score: %.4f\" % F1Score)\n",
    " \n",
    "#计算auc\n",
    "roc_auc = metrics.roc_auc_score(y_test, prediction_test_predprob)\n",
    "print(\"AUC-Score: %.4f\" % roc_auc)\n",
    " \n",
    "ks_score = ks(prediction_test, y_test)\n",
    "print(ks_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "f= open('/Users/tuyu/000000毕业设计/Flight_Delay/Model/model/lgb_model.pickle','wb')\n",
    "pickle.dump(lgb_model,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('/Users/tuyu/000000毕业设计/Flight_Delay/Model/model/lgb_model.pickle','rb') as fr:\n",
    "    lgb_model = pickle.load(fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from numpy import loadtxt,sort\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy\n",
    "\n",
    "lgb_dataset = feature.as_matrix()\n",
    "X = lgb_dataset[:,1:36]\n",
    "Y = lgb_dataset[:,36]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_offline = lgb_model.predict(x_test)\n",
    "lgb_offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.19244243, 0.03488925, 0.03387836, ..., 0.26797053, 0.11807531,\n",
       "       0.9837184 ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_test_predprob = lgb_model.predict_proba(x_test)[:,1]\n",
    "prediction_test_predprob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527720\n",
      "194111\n"
     ]
    }
   ],
   "source": [
    "print(len(prediction_test_predprob))\n",
    "print(sum(prediction_test_predprob >= 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = y_test.tolist()\n",
    "y_test = np.array([i for i in y_test])\n",
    "\n",
    "y_train = y_train.tolist()\n",
    "y_train = np.array([i for i in y_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48654120580492605"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#召回率\n",
    "returnResultScore = metrics.recall_score(lgb_offline, y_test)\n",
    "returnResultScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbdt_offline=(prediction_test_predprob >= 0.4) *1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96   1333609\n",
      "           1       0.86      0.49      0.62    194111\n",
      "\n",
      "    accuracy                           0.92   1527720\n",
      "   macro avg       0.89      0.74      0.79   1527720\n",
      "weighted avg       0.92      0.92      0.92   1527720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report \n",
    "print(classification_report(lgb_offline, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #XGBOOST使用原生态接口训练\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# dataset=feature.as_matrix()\n",
    "# train, val = train_test_split(dataset, test_size=0.25, random_state=36)\n",
    "# offline_test = val[:]\n",
    "# print(train.shape)\n",
    "# print(val.shape)\n",
    "\n",
    "\n",
    "# import time\n",
    "# import xgboost as xgb\n",
    "# start_time = time.time()\n",
    "# offline = 0\n",
    "# params={'booster':'gbtree',\n",
    "#     'objective': 'binary:logistic',\n",
    "#     'eval_metric':'auc',\n",
    "#     'gamma':0.1,\n",
    "#     'min_child_weight':1.1,\n",
    "#     'max_depth':7,\n",
    "#     'lambda':10,\n",
    "#     'subsample':0.7,\n",
    "#     'colsample_bytree':0.7,\n",
    "#     'colsample_bylevel':0.7,\n",
    "#     'eta': 0.01,\n",
    "#     'tree_method':'exact',\n",
    "#     'seed':1000,\n",
    "#     'nthread':12,\n",
    "#     'scale_pos_weight': 14\n",
    "#     }\n",
    "\n",
    "# params1={\n",
    "# 'booster':'gbtree',\n",
    "# 'objective': 'binary:logistic',\n",
    "# 'scale_pos_weight': 3,\n",
    "# #7183正样本\n",
    "# #55596条总样本\n",
    "# #差不多1:7.7这样子\n",
    "# 'gamma':0.2,  # 用于控制是否后剪枝的参数,越大越保守，一般0.1、0.2这样子。\n",
    "# 'max_depth':8, # 构建树的深度，越大越容易过拟合\n",
    "# 'lambda':3,  # 控制模型复杂度的权重值的L2正则化项参数，参数越大，模型越不容易过拟合。\n",
    "# 'subsample':0.7, # 随机采样训练样本\n",
    "# #'colsample_bytree':0.7, # 生成树时进行的列采样\n",
    "# 'min_child_weight':3, \n",
    "# # 这个参数默认是 1，是每个叶子里面 h 的和至少是多少，对正负样本不均衡时的 0-1 分类而言\n",
    "# #，假设 h 在 0.01 附近，min_child_weight 为 1 意味着叶子节点中最少需要包含 100 个样本。\n",
    "# #这个参数非常影响结果，控制叶子节点中二阶导的和的最小值，该参数值越小，越容易 overfitting。 \n",
    "# 'silent':0 ,#设置成1则没有运行信息输出，最好是设置为0.\n",
    "# 'eta': 0.03, # 如同学习率\n",
    "# 'seed':1000,\n",
    "# 'nthread':12,# cpu 线程数\n",
    "# 'eval_metric': 'auc'\n",
    "# }\n",
    "\n",
    "# plst = list(params.items())\n",
    "# num_rounds = 5000 # 迭代次数\n",
    "\n",
    "# y = train.标签\n",
    "# X = train.drop(['标签'],axis=1)\n",
    "\n",
    "# val_y = val.标签\n",
    "# val_X = val.drop(['标签'],axis=1)\n",
    "# #val_X = val[feature_list]\n",
    "\n",
    "# xgb_train = xgb.DMatrix(X, label=y)\n",
    "# xgb_val = xgb.DMatrix(val_X,label=val_y)\n",
    "\n",
    "# # return 训练和验证的错误率\n",
    "# watchlist = [(xgb_train, 'train'),(xgb_val, 'val')]\n",
    "# print(\"111\")\n",
    "# print (\"跑到这里了xgb.train\")\n",
    "# # training model \n",
    "# # early_stopping_rounds 当设置的迭代次数较大时，early_stopping_rounds 可在一定的迭代次数内准确率没有提升就停止训练\n",
    "# model = xgb.train(plst, xgb_train,num_boost_round=7000,evals=watchlist,early_stopping_rounds=500)\n",
    "# print (\"跑到这里了save_model\")\n",
    "# print (\"best best_ntree_limit\",model.best_ntree_limit)   #did not save the best,why?\n",
    "# print (\"best best_iteration\",model.best_iteration) #get it?\n",
    "# model.save_mdoel(\"D:/Desktop/xgb_model(原生接口).model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
